# FastPersianEval

### Scores {2025-3} :


Google Gemini 2.0 Pro Experimental = 68
Claude 3.7 Sonnet (api) = 64
Google Gemini 2.0 Flash Thinking = 56
ChatGPT 4o = 52
Google Gemini 2.0 Flash lite = 60
X Grok 3 Beta Think = 56
Deepseek V3 0324 (thirdparty api) = 32
Qwen 2.5 72B = 52
Deepseek V3 = 32
Google Gemini 2.0 Flash = 64
Google Gemma 3 27B = 56
Google Gemma 3 27B (thirdparty api) = 52
ChatGPT 4o mini = 24
Qwen 2.5 Max = 56
Qwen 2.5 VL 32B = 20
Deepseek R1 = 44
X Grok 3 Beta = 48
Mistral Le Chat = 44-56 (56 at second run)
Mistral Small 3.1 24B (thirdparty api) = 24
Meta Llama 3.1 70B (api) = 20
Qwen QwQ 32B = 48
Qwen 2.5 14B 1M = 8
Microsoft Copilot Think Deeper = 56
R1 Distill Llama 70B (thirdparty api) = 32
OLMo 2 32B = 12
ChatGPT o3 mini = 44
reka ai = 40
reka ai (thinking) = error
Qwen 2.5 Plus = 40
Qwen 2.5 Turbo = 28
Qwen 2.5 QVQ 72B Preview = 4
Qwen 2.5 Code 32B = 4
Mistral Small 3 24B (thirdparty api) = corrupted answers
Google Gemma 3 12B (thirdparty api) = 20
Reka Flash 3 (thirdparty api) = 20
Llama 3.3 70B (thirdparty api) = 28
Llama 3.2 3B (thirdparty api) = 16
Llama 3.1 8B (thirdparty api) = 40
*Google Gemma 3 4B (Local Q6_K)(42.6 tok/sec) = 20
Google Gemma 3 4B (thirdparty api) = 16
Google Gemma 3 1B (thirdparty api) = not answered
Microsoft Copilot = blocked
*Mistral Small 3 (Local IQ4_XS)(3.1 tok/sec) = 4 (loop answers)
*Google Gemma 3 12B (Local IQ3_XXS)(6.4 tok/sec) = 8
*Google Gemma 3 12B (Local Q4_K_S)(7.3 tok/sec) = 8
*Google Gemma 3 12B (Local Q6_K_L)(3.7 tok/sec) = 16
*LG EXAONE 7.8B (Local Q4_K_S)(31.5 tok/sec) = 28! (context overflow error)
*R1 Distill Llama 8B (Local IQ4_XS)( tok/sec) = corrupted answers
*Qwen 14B 1M (Local Q4_K_M)(4.3 tok/sec) = 16
*Google Gemma 3 1B (Local Q6_K_L)(99.8 tok/sec) = 12

Claude 3.7 Sonnet Reasoning (api) = 
Claude 3.5 Haiku (api) =
Meta Llama 3.1 405B (api) = 
Meta Llama 3.1 8B (api) =
