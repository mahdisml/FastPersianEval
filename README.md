# FastPersianEval

### Scores {2025-3} :

Claude 3.7 Sonnet Reasoning (api) = 
Claude 3.7 Sonnet (api) = 64
Google Gemini 2.0 Flash Thinking = 56
ChatGPT 4o = 52
Google Gemini 2.0 Pro Experimental = 68
Claude 3.5 Haiku (api) =
Google Gemini 2.0 Flash lite = 60
X Grok 3 Beta Think = 56
Deepseek V3 0324 (thirdparty api) =
Meta Llama 3.1 405B (api) = 
Qwen 2.5 72B = 52
Deepseek V3 = 32
Google Gemini 2.0 Flash = 64
Google Gemma 3 27B = 56
Google Gemma 3 27B (thirdparty api) =
ChatGPT 4o mini = 24
Qwen 2.5 Max = 56
Qwen 2.5 VL 32B = 20
Deepseek R1 = 44
X Grok 3 Beta = 48
Mistral Le Chat = 44-56 (56 at second run)
Mistral Small 3.1 24B (thirdparty api) =
Meta Llama 3.1 70B (api) =
Qwen QwQ 32B = 48
Qwen 2.5 14B 1M = 8
Microsoft Copilot Think Deeper =
R1 Distill Llama 70B (thirdparty api) =
OLMo 2 32B =
ChatGPT o3 mini = 44
Qwen 2.5 Plus = 40
Qwen 2.5 Turbo = 28
Qwen 2.5 QVQ 72B Preview = 4
Qwen 2.5 Code 32B = 4
Mistral Small 3 24B (thirdparty api) =
Google Gemma 3 12B (thirdparty api) =
Reka Flash 3 (thirdparty api) =
Llama 3.3 70B (thirdparty api) = 
Meta Llama 3.1 8B (api) =
Llama 3.2 3B (thirdparty api) = 
Google Gemma 3 4B (thirdparty api) =
Google Gemma 3 1B (thirdparty api) =
Microsoft Copilot = blocked
Mistral Small 3 (Local IQ4_XS)( tok/sec) =
Google Gemma 3 12B (Local IQ3_XXS)( tok/sec) =
Google Gemma 3 12B (Local Q4_K_S)( tok/sec) =
Google Gemma 3 12B (Local Q6_K_L)( tok/sec) =
LG EXAONE 7.8B (Local Q4_K_S)( tok/sec) =
R1 Distill Llama 8B (Local IQ4_XS)( tok/sec) =
Reka Flash 3 (Local Q4_K_S)( tok/sec) =
Qwen 14B 1M (Local Q4_K_M)( tok/sec) =
Google Gemma 3 1B (Local Q6_K_L)( tok/sec) =
Google Gemma 3 4B (Local Q6_K)( tok/sec) =
